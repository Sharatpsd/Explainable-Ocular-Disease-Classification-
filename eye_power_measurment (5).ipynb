{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Erhj35BkLdWe",
        "outputId": "0299199b-4fe9-4183-905a-3ac70e46e67b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Data Preparation...\n",
            "Total labeled images: 12784\n",
            "Myopia Class Distribution:\n",
            "myopia_class_str\n",
            "0    12305\n",
            "2      457\n",
            "1       22\n",
            "Name: count, dtype: int64\n",
            "Train/Validation/Test Split: 8692 / 1535 / 2557\n",
            "Found 8444 validated image filenames belonging to 3 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 248 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1487 validated image filenames belonging to 3 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 48 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2481 validated image filenames belonging to 3 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 76 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Building CNN Model...\n",
            "\n",
            "Starting Model Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 579ms/step - accuracy: 0.9378 - loss: 0.2689 - val_accuracy: 0.9606 - val_loss: 0.1682\n",
            "Epoch 2/10\n",
            "\u001b[1m  1/263\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 83ms/step - accuracy: 0.9688 - loss: 0.1411"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.9688 - loss: 0.1411 - val_accuracy: 0.9606 - val_loss: 0.1702\n",
            "Epoch 3/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 548ms/step - accuracy: 0.9631 - loss: 0.1676 - val_accuracy: 0.9613 - val_loss: 0.1675\n",
            "Epoch 4/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9688 - loss: 0.1367 - val_accuracy: 0.9613 - val_loss: 0.1653\n",
            "Epoch 5/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 556ms/step - accuracy: 0.9629 - loss: 0.1647 - val_accuracy: 0.9613 - val_loss: 0.1622\n",
            "Epoch 6/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.1237 - val_accuracy: 0.9613 - val_loss: 0.1643\n",
            "Epoch 7/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 554ms/step - accuracy: 0.9646 - loss: 0.1552 - val_accuracy: 0.9613 - val_loss: 0.1532\n",
            "Epoch 8/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9688 - loss: 0.1373 - val_accuracy: 0.9606 - val_loss: 0.1582\n",
            "Epoch 9/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 550ms/step - accuracy: 0.9594 - loss: 0.1621 - val_accuracy: 0.9606 - val_loss: 0.1561\n",
            "Epoch 10/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0194 - val_accuracy: 0.9599 - val_loss: 0.1612\n",
            "\n",
            "Evaluating Model on Test Set...\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 173ms/step - accuracy: 0.9640 - loss: 0.1421\n",
            "\n",
            "Final Test Set Accuracy: 96.19%\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 231ms/step\n",
            "\n",
            "--- Detailed Results ---\n",
            "Final Model Classification Accuracy: 96.21%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.96      1.00      0.98      2387\n",
            "     Class 1       0.00      0.00      0.00         2\n",
            "     Class 2       0.00      0.00      0.00        92\n",
            "\n",
            "    accuracy                           0.96      2481\n",
            "   macro avg       0.32      0.33      0.33      2481\n",
            "weighted avg       0.93      0.96      0.94      2481\n",
            "\n",
            "\n",
            "Confusion Matrix (True Labels vs. Predicted Labels):\n",
            " [[2387    0    0]\n",
            " [   2    0    0]\n",
            " [  92    0    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# ⚠️ IMPORTANT: Change this to the path where ALL your fundus images are stored.\n",
        "IMAGE_DIR = '/content/drive/MyDrive/thesis data/preprocessed_images'\n",
        "CSV_FILE = '/content/drive/MyDrive/thesis data/full_df.csv'\n",
        "IMG_SIZE = 224 # Standard size for ResNet50\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 3 # 0: Non-Myopia, 1: Low/Mild Myopia, 2: High/Pathological Myopia\n",
        "EPOCHS = 10 # Start with 10, tune as needed\n",
        "\n",
        "# --- END CONFIGURATION ---\n",
        "\n",
        "# 1. Define Classification Mapping based on ODIR-5K Keywords\n",
        "def classify_myopia(keywords):\n",
        "    \"\"\"Assigns a class index based on diagnostic keywords.\"\"\"\n",
        "    if pd.isna(keywords) or keywords == 'nan':\n",
        "        return 0 # Default to Non-Myopia if keywords are missing\n",
        "\n",
        "    keywords = keywords.lower()\n",
        "\n",
        "    # Class 2: Strong/Very Strong Myopia (M2)\n",
        "    if 'pathological myopia' in keywords or 'high myopia' in keywords:\n",
        "        return 2\n",
        "\n",
        "    # Class 1: Mild/Low Myopia (M1)\n",
        "    if 'myopia' in keywords or 'refractive error' in keywords:\n",
        "        return 1\n",
        "\n",
        "    # Class 0: Non-Myopia (N)\n",
        "    return 0\n",
        "\n",
        "# 2. Data Preparation and Label Generation\n",
        "print(\"Starting Data Preparation...\")\n",
        "df = pd.read_csv(CSV_FILE)\n",
        "\n",
        "# Reshape the data to have one row per eye (Left and Right)\n",
        "data_left = df[['Left-Fundus', 'Left-Diagnostic Keywords']].rename(\n",
        "    columns={'Left-Fundus': 'filename', 'Left-Diagnostic Keywords': 'keywords'}\n",
        ")\n",
        "data_right = df[['Right-Fundus', 'Right-Diagnostic Keywords']].rename(\n",
        "    columns={'Right-Fundus': 'filename', 'Right-Diagnostic Keywords': 'keywords'}\n",
        ")\n",
        "\n",
        "full_data = pd.concat([data_left, data_right], ignore_index=True)\n",
        "\n",
        "# Generate the numerical class labels\n",
        "full_data['myopia_class'] = full_data['keywords'].apply(classify_myopia)\n",
        "\n",
        "# Filter out rows where image file is missing (e.g., placeholder in the CSV)\n",
        "full_data = full_data[full_data['filename'].apply(lambda x: os.path.splitext(x)[1] in ['.jpg', '.png'])]\n",
        "\n",
        "# Convert the label column to string for Keras FlowFromDataFrame\n",
        "full_data['myopia_class_str'] = full_data['myopia_class'].astype(str)\n",
        "\n",
        "print(f\"Total labeled images: {len(full_data)}\")\n",
        "print(f\"Myopia Class Distribution:\\n{full_data['myopia_class_str'].value_counts()}\")\n",
        "\n",
        "# 3. Data Split\n",
        "train_df, test_df = train_test_split(\n",
        "    full_data,\n",
        "    test_size=0.2, # 20% for testing (which will also include validation)\n",
        "    stratify=full_data['myopia_class_str'],\n",
        "    random_state=42\n",
        ")\n",
        "train_df, val_df = train_test_split(\n",
        "    train_df,\n",
        "    test_size=0.15, # 15% of the remaining data for validation (~12% of total)\n",
        "    stratify=train_df['myopia_class_str'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Train/Validation/Test Split: {len(train_df)} / {len(val_df)} / {len(test_df)}\")\n",
        "\n",
        "\n",
        "# 4. Image Loading and Preprocessing (Data Generators)\n",
        "# Data augmentation for training to prevent overfitting\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Only rescaling (normalization) for validation and test sets\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create Generators\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=IMAGE_DIR,\n",
        "    x_col='filename',\n",
        "    y_col='myopia_class_str',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_generator = val_test_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory=IMAGE_DIR,\n",
        "    x_col='filename',\n",
        "    y_col='myopia_class_str',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Test generator (do not shuffle)\n",
        "test_generator = val_test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    directory=IMAGE_DIR,\n",
        "    x_col='filename',\n",
        "    y_col='myopia_class_str',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# 5. Model Building (Transfer Learning with ResNet50)\n",
        "print(\"\\nBuilding CNN Model...\")\n",
        "# Load ResNet50 pre-trained on ImageNet weights\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "# Freeze the convolutional layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom classification layers (the 'head')\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x) # Reduces spatial dimensions\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(NUM_CLASSES, activation='softmax')(x) # Final output layer for 3 classes\n",
        "\n",
        "# Define the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# 6. Training and Evaluation\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "print(\"\\nStarting Model Training...\")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
        ")\n",
        "\n",
        "# Evaluate on the Test Set\n",
        "print(\"\\nEvaluating Model on Test Set...\")\n",
        "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // BATCH_SIZE)\n",
        "\n",
        "print(f\"\\nFinal Test Set Accuracy: {test_accuracy*100:.2f}%\")\n",
        "\n",
        "# Generate detailed classification report\n",
        "test_generator.reset()\n",
        "Y_pred = model.predict(test_generator, steps=test_generator.samples // BATCH_SIZE + 1)\n",
        "y_pred_classes = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "# Map numeric predictions back to class names\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "# Fixed line:\n",
        "y_true_indices = test_generator.classes\n",
        "\n",
        "# Match the length of true labels to predictions (this is complex due to the generator size)\n",
        "# For simplicity, we limit the comparison to the number of predictions made\n",
        "y_true_limited = y_true_indices[:len(y_pred_classes)]\n",
        "\n",
        "# Calculate final accuracy and report\n",
        "final_accuracy = accuracy_score(y_true_limited, y_pred_classes)\n",
        "report = classification_report(y_true_limited, y_pred_classes, target_names=[f'Class {c}' for c in class_labels])\n",
        "conf_matrix = confusion_matrix(y_true_limited, y_pred_classes)\n",
        "\n",
        "print(\"\\n--- Detailed Results ---\")\n",
        "print(f\"Final Model Classification Accuracy: {final_accuracy*100:.2f}%\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n",
        "print(\"\\nConfusion Matrix (True Labels vs. Predicted Labels):\\n\", conf_matrix)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}